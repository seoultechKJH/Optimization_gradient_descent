{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b2d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42897847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  Price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston() # boston 데이터 로드\n",
    "bos = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "bos['Price'] = boston.target\n",
    "bos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc603ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price      1.000000\n",
       "RM         0.695360\n",
       "ZN         0.360445\n",
       "B          0.333461\n",
       "DIS        0.249929\n",
       "CHAS       0.175260\n",
       "AGE       -0.376955\n",
       "RAD       -0.381626\n",
       "CRIM      -0.388305\n",
       "NOX       -0.427321\n",
       "TAX       -0.468536\n",
       "INDUS     -0.483725\n",
       "PTRATIO   -0.507787\n",
       "LSTAT     -0.737663\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = bos.corr()\n",
    "corr['Price'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe83c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "data = preprocessing.scale(bos.drop(columns = ['Price']))\n",
    "y = preprocessing.scale(bos['Price']) #target값 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31746b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.c_[np.ones(data.shape[0]), data] #[상수항(1), 전체변수]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "047465e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0001 #learning rate = 0.0001\n",
    "m = y.size # 개수 - 506개\n",
    "np.random.seed(10)\n",
    "theta = np.random.rand(14) #0~1 사이의 난수 14개 생성 (파라미터 초기값)\n",
    "def gradient_descent(x, y, m, theta, alpha):\n",
    "    cost_list = []\n",
    "    theta_list = []\n",
    "    prediction_list = []\n",
    "    gradient_list = []\n",
    "    run = True\n",
    "    cost_list.append(1e10) #cost 초기값 = 10의 10승\n",
    "    i = 0\n",
    "    while run: #run이 True일 경우\n",
    "        prediction = np.dot(x, theta) #벡터 x와 벡터 theta 간의 내적으로 예측치 계산\n",
    "        prediction_list.append(prediction) #예측치 기록\n",
    "        error = prediction - y #예측치와 실제값의 오차 계산\n",
    "        cost = 1/(2*m) * np.dot(error.T, error) # 오차 제곱합을 2m으로 나눔 (gradient descent를 위해 편의상 2m으로 설정)\n",
    "        cost_list.append(cost) #cost 기록\n",
    "        if len(theta_list) == 0: #파라미터 초기값으로 1회 수행\n",
    "            gradient = - (1/m) * np.dot(x.T, error)\n",
    "            theta = theta - (alpha * (1/m) * np.dot(x.T, error)) #파라미터 업데이트\n",
    "            theta_list.append(theta) #파라미터 기록\n",
    "            gradient_list.append(gradient) #gradient 기록\n",
    "        elif len(theta_list) != 0: #모멘텀을 반영한 그래디언트 생성\n",
    "            before_gradient = gradient_list[-1]\n",
    "            beta = 0.5\n",
    "            new_gradient = beta * before_gradient - (1-beta) * (1/m) * np.dot(x.T, error)\n",
    "            theta = theta + alpha * new_gradient #파라미터 업데이트\n",
    "            theta_list.append(theta) #파라미터 기록\n",
    "            gradient_list.append(new_gradient) #gradient 기록\n",
    "            \n",
    "        if cost_list[i] - cost_list[i+1] < 1e-9: #현재 cost와 전단계 cost 차이가 작으면 수렴이므로 중단\n",
    "            run = False\n",
    "        \n",
    "        i += 1\n",
    "    cost_list.pop(0) #초기 cost값 기록 삭제\n",
    "    return prediction_list, cost_list, theta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62130920",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list, cost_list, theta_list = gradient_descent(x, y, m, theta, alpha)\n",
    "theta = theta_list[-1] #마지막 수렴된 파라미터 벡터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3913258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost_list)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show() #반복에 따른 cost 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bac21849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선형회귀에 의한 MSE : 0.2595147\n",
      "gradient descent에 의한 MSE : 0.2595147\n"
     ]
    }
   ],
   "source": [
    "y_pred = theta[0] + theta[1] * x[:, 1] + theta[2] * x[:, 2] + theta[3] * x[:, 3] + theta[4] * x[:, 4] + theta[5] * x[:, 5] + theta[6] * x[:, 6] + theta[7] * x[:, 7] + theta[8] * x[:, 8] + theta[9] * x[:, 9] + theta[10] * x[:, 10] + theta[11] * x[:, 11] + theta[12] * x[:, 12] + theta[13] * x[:, 13] #최종 파라미터 벡터로 선형식 구성하고 예측값 산출\n",
    "\n",
    "MSE_e = ((y_pred-y)**2).mean() #선형식에 의한 오차제곱 평균 계산\n",
    "MSE_GD = ((prediction_list[-1]-y)**2).mean() #gradient descent에 의한 오차제곱 평균 계산\n",
    "\n",
    "print('선형회귀에 의한 MSE : {}'.format(round(MSE_e, 7)))\n",
    "print('gradient descent에 의한 MSE : {}'.format(round(MSE_GD, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b2d12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
